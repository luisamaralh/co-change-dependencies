{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.eda_methods import show_barplot, load_data, load_data_all\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "pd.set_option('display.max_colwidth', 125)\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT - Figure out how to correctly convert old hashes to new hashes\n",
    "\n",
    "# project_name = 'zeppelin'\n",
    "# try:\n",
    "#     tmp =\\\n",
    "#         pd.read_csv(\n",
    "#             'assets/data/{0}/new_{0}_commits.csv'.format(project_name),\n",
    "#             nrows=None,\n",
    "#             header=None\n",
    "#         )\n",
    "# except UnicodeDecodeError:\n",
    "#     tmp =\\\n",
    "#         pd.read_csv(\n",
    "#             'assets/data/{0}/new_{0}_commits.csv'.format(project_name),\n",
    "#             nrows=None,\n",
    "#             header=None,\n",
    "#             encoding='utf-16'\n",
    "#         )\n",
    "# tmp = tmp.set_index(0).apply(pd.to_datetime, axis=1)\n",
    "# tmp['dates_match'] = tmp.apply(lambda x: x.duplicated().sum(), axis=1).astype('bool')\n",
    "\n",
    "# # finds\n",
    "# grouped = tmp.groupby(2)\n",
    "# g_index =\\\n",
    "#     [\n",
    "#             x for x in grouped[1].apply(\n",
    "#                 lambda x: pd.to_datetime(x[0], utc=True) \n",
    "#                 if (x.count() > 1).sum() else ''\n",
    "#             ).values if x\n",
    "#     ]\n",
    "# tmp = tmp.reset_index().set_index(1)\n",
    "# tmp.index = pd.to_datetime(tmp.index, utc=True, infer_datetime_format=True)\n",
    "\n",
    "# transforms date column into datetime_index\n",
    "# new_commits =\\\n",
    "#     pd.Series(\n",
    "#         tmp[0].values,\n",
    "#         index=pd.to_datetime(\n",
    "#                 tmp[1].values,\n",
    "#                 infer_datetime_format=True,\n",
    "#                 utc=True\n",
    "#             )\n",
    "#     )\n",
    "# new_commits.name = project_name"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "old, new, cc, bic = load_data_all()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows duplicated bug introducing commits (BIC) for each project\n",
    "print('Total and duplicated bic for each project:\\n\\n\\t\\t\\t(total, duplicated)')\n",
    "bic.groupby(level=0).apply(lambda x: (x.count(), x.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes duplicated BICs\n",
    "print('Total BICs after removal of duplicates:\\n')\n",
    "\n",
    "project_bic = bic.groupby(level=0)\n",
    "\n",
    "# saves unique BICs\n",
    "ubic = project_bic.apply(lambda x: x.drop_duplicates(keep='first')).droplevel(0, axis=0)\n",
    "\n",
    "print(ubic.groupby(level=0, axis=0).count())\n",
    "del bic"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shows all conflicting 'created_at' commits\n",
    "proceed with manual investigation of how to solve this (HUGE ISSUE!!!)\n",
    "'''\n",
    "# old.droplevel(0, axis=0)[old.droplevel(0, axis=0).index.duplicated(keep=False)]\n",
    "# new.droplevel(0, axis=0)[new.droplevel(0, axis=0).index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new.reset_index().iloc[old.reset_index().index][0].values\n",
    "'''\n",
    "prints projects with different number of commits\n",
    "'''\n",
    "new_g = new.groupby(level=0)\n",
    "old_g = old.groupby(level=0)\n",
    "\n",
    "for ng, og in zip(new_g, old_g):\n",
    "    # ng[1] = ng[1][ng[1].index.isin(og[1].index)]\n",
    "    if len(ng[1])-1 != len(og[1]):\n",
    "        print(ng[0], (len(ng[1]) - len(og[1]))-1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new.reset_index().iloc[old.reset_index().index][0].values\n",
    "'''\n",
    "ensures that only commits present in 'old' are considered\n",
    "'''\n",
    "new_g = new.groupby(level=0)\n",
    "old_g = old.groupby(level=0)\n",
    "tmp = []\n",
    "\n",
    "for ng, og in zip(new_g, old_g):\n",
    "    tmp.append(ng[1][ng[1].index.isin(og[1].index)])\n",
    "\n",
    "new = pd.concat(tmp)\n",
    "del tmp\n",
    "# del new_g, old_g"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates old and new commits to facilitate conversion\n",
    "convert = pd.DataFrame()\n",
    "\n",
    "convert['old_hash'] = old\n",
    "convert['new_hash'] =\\\n",
    "    new.reset_index()\\\n",
    "    .iloc[old.reset_index()\\\n",
    "    .index][0].values\n",
    "\n",
    "# converts bic commits to their equivalent in 'new'\n",
    "ubic =\\\n",
    "    convert.set_index('old_hash')\\\n",
    "    .squeeze()[ubic.values]\\\n",
    "    .dropna()\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "del convert"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creates a dataframe to support conversion of old hashes into new ones\n",
    "# conv_df = pd.DataFrame()\n",
    "\n",
    "# conv_df['old_hash'] = old.sort_index()\n",
    "# conv_df['new_hash'] =\\\n",
    "#     new.sort_index()\\\n",
    "#     .reset_index(drop=True)[\n",
    "#         old.sort_index()\\\n",
    "#         .reset_index(drop=True)\\\n",
    "#         .index\n",
    "#     ].values"
   ]
  }
 ]
}